import sys

if len(sys.argv) < 2:
	print \
"""Usage: ./%s <output_file> <coordinate_file>""" % (sys.argv[0])
	sys.exit(1)

import numpy
import scipy
import scipy.linalg
from parser.import_cp1_csv import import_cp1_csv_files
import mahal_dist
import cluster


class QualityControl:
	pass


project_name = 'fabian' #'miriam'


# make some configuration depending on the project
if project_name == 'fabian':
	objects = ['cells','nucleus']
	path = '\\\\almf\\almf\\group\\ALMFstuff\\Tischi\\Fabian_Heiko\\IF_NPC1_results\\'
	#data = 'MergedOUT_101103.mat''
	file_images = '../data/Merged_clng_new_Image.xls'
	file_cells = '../data/Merged_clng_new_cells.xls'
	file_nuclei = '../data/Merged_clng_new_nucleus.xls'
	channels = []
	channels.append('Nucleus')
	channels.append('NPC1')
	channels.append('Vesicle')
	channelsOrig = []
	channelsOrig.append('Dapi')
	channelsOrig.append('GFP')
	channelsOrig.append('Cy3')
	channelsSeg = []
	channelsSeg.append('Segmentation')
	channelsSeg.append('VesicleSeg')
	color = '0.0.255-0.255.0-255.0.0-255.255.255-255.255.255-255.255.255'
	treatmentControl = 'IF_NPC1_Lamp1_scram1'
	qc = QualityControl()
	qc.computeMahalanobis = True
	qc.makeMedianMontage = False
	qc.minAreaBG = 50000 # pixels
	qc.minNucSize = 5000
elif project_name == 'miriam':
	path = '\\\\almf\\almf\\group\\ALMFstuff\\Tischi\\Miriam\\VSVG_release_morphology_results\\'
	file_images = '../data/CP-output--Fabian_Image.xls'
	file_cells = '../data/CP-output--Fabian_cells.xls'
	file_nuclei = '../data/CP-output--Fabian_nucleus.xls'
	channels = []
	channels.append('Nucleus')
	channels.append('Protein')
	channels.append('Vesicle')
	channelsOrig = []
	channelsOrig.append('dapi')
	channelsOrig.append('yfp')
	channelsOrig.append('cy5')
	channelsSeg = []
	channelsSeg.append('Segmentation')
	channelsSeg.append('ProteinSeg')
	color = '0.0.255-0.255.0-255.0.0-255.255.255-255.255.255-255.255.255'
	treatmentControl = 'wt_00'
	evaluationChannel = 'Protein'
	qc = QualityControl()
	qc.computeMahalanobis = True
	qc.makeMedianMontage = False
	qc.minAreaBG = 50000 # pixels
	
qc.minDist_X_left = 100 #300
qc.minDist_X_right = 100
qc.minDist_Y_top = 100
qc.minDist_Y_bottom = 100 # todo: check where top and bottom is

qc.imageX = 1344
qc.imageY = 1024
qc.imageSize = qc.imageX * qc.imageY

qc.minCytoNucAreaFrac = 1.5
qc.maxCytoNucAreaFrac = 15

qc.minCells = 1
qc.maxCells = 300


# import data from files
data = import_cp1_csv_files(file_images,file_cells,file_nuclei)



print 'number of images: %d' % len(data.images)
print 'number of cells: %d' % len(data.cells)
print 'number of nuclei: %d' % len(data.nuclei)



# deletes listed cells and nuclei from the passed feature array
# returns the new feature array new_features
def delete_objects_from_feature_array(ids, features):
	new_features = numpy.array(0.0)
	new_features.resize(
				features.shape[0] - len(ids), features.shape[1]
	)
	i = 0
	for j in xrange(features.shape[0]):
		if not j in ids:
			new_features[i] = features[j]
			i += 1
	return new_features




# deletes listed cells and nuclei from a apc_data structure
def delete_images(qc, ids, apc_data):
    qc.new_imgId_to_old_imgId = {}
    qc.old_imgId_to_new_imgId = {}
    rowIdCorrection = 0
    temp = 0
    for id in ids:
        del data.images[id - temp]
        temp += 1
    
    for treatment in data.treatments.values():
        temp_ids = []
        for i in xrange(len(treatment.images)):
            img = treatment.images[i]
            if img.rowId in ids:
                temp_ids.append(i)
    	temp = 0
    	for id in temp_ids:
    	    del treatment.images[id - temp]
    	    temp += 1



# deletes listed cells and nuclei from a apc_data structure
def delete_objects(qc, ids, apc_data):

	qc.new_rowId_to_old_rowId = {}
	qc.old_rowId_to_new_rowId = {}
	rowIdCorrection = 0
	for i in xrange(len(data.cells)):
		cell = data.cells[i]
		nucleus = data.nuclei[i]
		old_rowId = cell.rowId
		cell.rowId += rowIdCorrection
		nucleus.rowId += rowIdCorrection
		if i in ids:
			cell.state = 'invalid'
			nucleus.state = 'invalid'
			rowIdCorrection -= 1
			qc.old_rowId_to_new_rowId[old_rowId] = -1
		else:
			qc.new_rowId_to_old_rowId[cell.rowId] = old_rowId
			qc.old_rowId_to_new_rowId[old_rowId] = cell.rowId
	ids.sort(reverse=True)
	for i in ids:
		del data.cells[i]
		del data.nuclei[i]

	new_objFeatures = delete_objects_from_feature_array(ids, data.objFeatures)
	del data.objFeatures
	data.objFeatures = new_objFeatures
	
	for im in data.images:
		ids2 = []
		for i in xrange(len(im.cells)):
			if im.cells[i].state == 'invalid':
				ids2.append(i)
		ids2.reverse()
		for j in ids2:
			del im.cells[j]
			del im.nuclei[j]
		new_objFeatures = delete_objects_from_feature_array(ids2, im.objFeatures)
		del im.objFeatures
		im.objFeatures = new_objFeatures
		
	for tr in data.treatments.values():
		ids2 = []
		for i in xrange(len(tr.cells)):
			if tr.cells[i].state == 'invalid':
				ids2.append(i)
		ids2.reverse()
		for j in ids2:
			del tr.cells[j]
			del tr.nuclei[j]
		new_objFeatures = delete_objects_from_feature_array(ids2, tr.objFeatures)
		del tr.objFeatures
		tr.objFeatures = new_objFeatures


# quality control of the data
def quality_control(qc, data):
    delete_img_ids = []
    delete_obj_ids = []
    for image in data.images:
    
    	# maximum number of cells
    	if (len(image.cells) > qc.maxCells):
    		#print 'too_many_cells'
    		image.state = 'too_many_cells'
    		delete_img_ids.append(image.rowId)
    		#sys.exit(-1)
    	
    	# minimal number of background pixels
    	cellFeatureId = data.cellFeatureIds['AreaShape_Area']
    	areaOccupiedByCells = sum(image.objFeatures[:,cellFeatureId])
    	if (qc.imageSize - areaOccupiedByCells < qc.minAreaBG):
    		#print 'not_enough_bg_Pixels for image(%d): %s' % (image.rowId,image.name)
    		image.state = 'not_enough_bg_pixels'
    		#sys.exit(-1)
    		delete_img_ids.append(image.rowId)
    
    	# cells are at image periphery
    	featureId = data.nucleusFeatureIds['Location_Center_X']
    	cellsOk = (image.objFeatures[:,featureId] > qc.minDist_X_left)
    	cellsOk = numpy.logical_and(cellsOk,
    				(image.objFeatures[:,featureId] < qc.imageX-qc.minDist_X_right)
    	)
    	featureId = data.nucleusFeatureIds['Location_Center_Y']
    	cellsOk = numpy.logical_and(cellsOk,
    				(image.objFeatures[:,featureId] > qc.minDist_Y_top)
    	)
    	cellsOk = numpy.logical_and(cellsOk,
    				(image.objFeatures[:,featureId] < qc.imageY-qc.minDist_Y_bottom)
    	)
    	# minimum nucleus area
    	nucleusFeatureId = data.nucleusFeatureIds['AreaShape_Area']
    	#thresholdNucleusArea = numpy.median(image.objFeatures[:,featureId] \
    	#              - 2 * numpy.mean( numpy.abs(
    	#                      image.objFeatures[:,featureId]
    	#                      - numpy.mean(image.objFeatures[:,featureId])
    	#              ) )
    	#)
    	cellsOk = numpy.logical_and(cellsOk,
    				(image.objFeatures[:,nucleusFeatureId] > qc.minNucSize)
    	)
    
    	# minimum relative cytoplasm area
    	#cellFeatureId = data.cellFeatureIds['AreaShape_Area']
    	cellsOk = numpy.logical_and(cellsOk,
    				(image.objFeatures[:,cellFeatureId]
    	)
    						  > qc.minCytoNucAreaFrac * image.objFeatures[:,nucleusFeatureId]
    	)
    
    	# maximum relative cytoplasm area
    	cellsOk = numpy.logical_and(cellsOk,
    				(image.objFeatures[:,cellFeatureId]
    				  < qc.maxCytoNucAreaFrac * image.objFeatures[:,nucleusFeatureId])
    	)
    
    	# check wether there are enough Ok cells left
    	numberOfOkCells = numpy.sum(cellsOk)
    	if (numberOfOkCells < qc.minCells):
            delete_img_ids.append(image.rowId)
            #print 'not_enough_OKcells for image(%d): %s' % (image.rowId,image.name)
            if image.state == 'OK':
                image.state = 'not_enough_OK_cells'
    		#sys.exit(-1)
    
    	# add bad cells and nuclei to the cleanup list
    	for i in xrange(len(cellsOk)):
    		if not cellsOk[i]:
    			delete_obj_ids.append(i + image.cells[0].rowId)

    for img in delete_img_ids:
        for cell in data.images[img].cells:
            if not cell.rowId in delete_obj_ids:
                delete_obj_ids.append(cell.rowId)    
    
    # finally cleanup all bad objects
    delete_objects(qc, delete_obj_ids, data)
    
    delete_images(qc, delete_img_ids, data)

# do some validation of the data
quality_control(qc, data)

print 'number of images: %d' % len(data.images)
print 'number of cells: %d' % len(data.cells)
print 'number of nuclei: %d' % len(data.nuclei)

# select features
featureIds = []
featureIds.append(data.nucleusFeatureIds['AreaShape_Area'])
#featureIds.append(data.nucleusFeatureIds['AreaShape_Perimeter'])
featureIds.append(data.cellFeatureIds['AreaShape_Area'])
#featureIds.append(data.cellFeatureIds['AreaShape_Perimeter'])
featureIds.append(data.cellFeatureIds['MQ_number_SegSmall_SegVesicle_Vesicle'])
featureIds.append(data.cellFeatureIds['MQ_area_SegSmall_mean_SegVesicle_Vesicle'])
featureIds.append(data.cellFeatureIds['MQ_intensMean_SegSmall_Foreground_mean_SegVesicle_Vesicle'])

def multiply_m(A,B):
	C = numpy.array(0.0)
	C.resize(A.shape[0],B.shape[1])
	for i in xrange(B.shape[1]):
		for j in xrange(A.shape[0]):
			sum = 0.0
			for k in xrange(A.shape[1]):
				sum += A[j,k] * B[k,i]
			C[j,i] = sum
	return C


if qc.computeMahalanobis:
    mahalFeatureIds = list(featureIds)
    ref = data.treatments[treatmentControl].objFeatures[:,mahalFeatureIds]
    #ref = data.objFeatures[:,mahalFeatureIds]
    #test = data.objFeatures[:,mahalFeatureIds]
    
    badFeatures = []
    # don't use features with zero std-deviation for the mahalanobis distance
    for i in xrange(len(featureIds)):
    	id = featureIds[i]
    	stddev = numpy.std(data.objFeatures[:,id])
    	if stddev <= 0:
    		badFeatureIds.append(id)
    temp = 0
    for i in badFeatures:
        print 'deleting feature %d' % i
    	del mahalFeatureIds[i - temp]
    	temp += 1
    
    ref = data.treatments[treatmentControl].objFeatures[:,mahalFeatureIds]
        
    # don't use correlated features for mahalanobis distance
    ccm = numpy.corrcoef(ref, rowvar=0, bias=0)

    badFeatures = []
    # maximum correlation allowed
    corrThreshold = 0.8
    for i in xrange(ccm.shape[0]):
    	for j in xrange(i+1, ccm.shape[1]):
    		if abs(ccm[i,j]) > corrThreshold:
    			badFeatures.append(i)
    			break
    temp = 0
    for i in badFeatures:
        print 'deleting feature %d' % i
    	del mahalFeatureIds[i - temp]
    	temp += 1
    
    ref = data.treatments[treatmentControl].objFeatures[:,mahalFeatureIds]
    test = data.objFeatures[:,mahalFeatureIds]
    
    fraction = 0.7
    #fraction = 1.0
    d_mahal,controlMean,controlIds = mahal_dist.mahalanobis_distance(ref, test, fraction)

    treatment_id_to_name = []
    dist_median_by_treatment = numpy.array(0.0)
    dist_median_by_treatment.resize(len(data.treatments))
    for i in xrange(len(data.treatments.values())):
        treatment = data.treatments.values()[i]
        dist = numpy.zeros(len(treatment.cells))
        for j in xrange(len(treatment.cells)):
            rowId = treatment.cells[j].rowId
            dist[j] = d_mahal[rowId]
        dist_median_by_treatment[i] = numpy.median(dist)
        treatment_id_to_name.append(treatment.name)
    
    # calculate the transformation matrix for the mahalanobis space
    control_features = data.treatments[treatmentControl].objFeatures[:,mahalFeatureIds]
    if controlIds == None:
        control_features = data.treatments[treatmentControl].objFeatures[:,mahalFeatureIds]
    else:
        control_features = data.treatments[treatmentControl].objFeatures[controlIds][:,mahalFeatureIds]
    cov = mahal_dist.covariance_matrix( control_features )
    eigenvalues,eigenvectors = scipy.linalg.eigh(cov)
    diag_m = numpy.diag( 1.0 / scipy.sqrt(eigenvalues) )
    trans_m = numpy.dot(numpy.dot(eigenvectors,diag_m),eigenvectors.transpose())
    #trans_m = multiply_m(eigenvectors,diag_m)
    #trans_m = multiply_m(trans_m,eigenvectors.transpose())
    # transformate data points into mahalanobis space
    trans_features = data.objFeatures[:,mahalFeatureIds] - controlMean
    trans_features = numpy.dot(
    		trans_m, trans_features.transpose() ).transpose()


    controlIds = None
    #for i in xrange(trans_features.shape[0]):
    #	dist = numpy.sum(trans_features[i,:]**2)
    #	d_mahal[i] = dist
    if controlIds == None:
        tmp_array = numpy.array(0.0)
        tmp_array.resize(len(data.treatments[treatmentControl].cells))
    #tmp_array2 = numpy.array(0.0)
    #tmp_array2.resize(len(data.treatments[treatmentControl].cells),trans_features.shape[1])
        for i in xrange(tmp_array.shape[0]):
            tmp_array[i] = d_mahal[ data.treatments[treatmentControl].cells[i].rowId ]
            #tmp_array2[i] = trans_features[ data.treatments[treatmentControl].cells[i].rowId ]
    else:
        tmp_array = numpy.array(0.0)
        tmp_array.resize(controlIds.shape[0])
        for i in xrange(tmp_array.shape[0]):
            tmp_array[i] = d_mahal[ data.treatments[treatmentControl].cells[i].rowId ]
        
    medianMahalCtrl = numpy.median(tmp_array)
    meanMahalCtrl = numpy.mean(tmp_array)
    madMahalCtrl = numpy.mean(numpy.abs(tmp_array - meanMahalCtrl))
    mahalScore1 = (d_mahal - medianMahalCtrl) / madMahalCtrl
    dist = numpy.sum(trans_features[:,:]**2,1)
    if controlIds == None:
        tmp_array = numpy.array(0.0)
        tmp_array.resize(len(data.treatments[treatmentControl].cells))
    #tmp_array2 = numpy.array(0.0)
    #tmp_array2.resize(len(data.treatments[treatmentControl].cells),trans_features.shape[1])
        for i in xrange(tmp_array.shape[0]):
            tmp_array[i] = d_mahal[ data.treatments[treatmentControl].cells[i].rowId ]
            #tmp_array2[i] = trans_features[ data.treatments[treatmentControl].cells[i].rowId ]
    else:
        tmp_array = numpy.array(0.0)
        tmp_array.resize(controlIds.shape[0])
        for i in xrange(tmp_array.shape[0]):
            tmp_array[i] = d_mahal[ data.treatments[treatmentControl].cells[i].rowId ]
    for i in xrange(tmp_array.shape[0]):
        tmp_array[i] = dist[ data.treatments[treatmentControl].cells[i].rowId ]
    medianMahalCtrl = numpy.median(tmp_array)
    meanMahalCtrl = numpy.mean(tmp_array)
    madMahalCtrl = numpy.mean(numpy.abs(tmp_array - meanMahalCtrl))
    mahalScore2 = (dist - medianMahalCtrl) / madMahalCtrl

    #for i in xrange(d_mahal.shape[0]):
    #	print 'i=%d: %f (new_i=%d), cell_area=%f, cell_perimeter=%f, nucleus_area=%f, nucleus_perimeter=%f' \
    #		% (qc.new_rowId_to_old_rowId[i],d_mahal[i],i,
    #			data.objFeatures[i,data.cellFeatureIds['AreaShape_Area']] * 10**(-4),
    #			data.objFeatures[i,data.cellFeatureIds['AreaShape_Perimeter']] * 10**(-2),
    #			data.objFeatures[i,data.nucleusFeatureIds['AreaShape_Area']] * 10**(-3),
    #			data.objFeatures[i,data.nucleusFeatureIds['AreaShape_Perimeter']] * 10**(-2))
    fout = open(sys.argv[1],'wb')
    str = 'treatment\tmedian mahalanobis distance\n'
    fout.write(str)
    for i in xrange(dist_median_by_treatment.shape[0]):
        str = '%s\t%f\n' % (treatment_id_to_name[i], dist_median_by_treatment[i])
        fout.write(str)
    str = '\n'
    fout.write(str)
    fout.write(str)
    fout.write(str)
    str = 'rowId\td_mahal\tmahal_score1\tdist\tmahal_score2'
    for featureId in mahalFeatureIds:
    	str += '\t%s' % featureId
    str += '\tnew_rowId\n'
    fout.write(str)
    for i in xrange(d_mahal.shape[0]):
    	str = '%d\t%f\t%f\t%f\t%f' % ( qc.new_rowId_to_old_rowId[i], d_mahal[i], mahalScore1[i], dist[i], mahalScore2[i])
    	for featureId in mahalFeatureIds:
    		str += '\t%f' % data.objFeatures[i,featureId]
    	str += '\t%d\n' % i
    	fout.write(str)
    fout.close()
    
    fout = open(sys.argv[2],'wb')
    for i in xrange(d_mahal.shape[0]):
    	str = ''
    	for featureId in mahalFeatureIds:
    		str += '%f\t' % data.objFeatures[i,featureId]
    	str = str[:-1]
    	str += '\n'
    	fout.write(str)
    fout.close()
    
    if len(sys.argv) > 3:
    	sortIds = d_mahal.argsort()
    	fout = open(sys.argv[3],'wb')
    	str = 'rowId\td_mahal\tx\ty'
    	for featureId in mahalFeatureIds:
    		str += '\t%s' % featureId
    	str += '\tnew_rowId\n'
    	fout.write(str)
    	for j in xrange(d_mahal.shape[0]):
    		i = sortIds[j]
    		fout.write('%d\t%f\t%f\t%f\t%f\t%f\t%f\t%f\t%d\n' \
    			% ( qc.new_rowId_to_old_rowId[i], d_mahal[i],
    				data.objFeatures[i,data.cellFeatureIds['Location_Center_X']] * 10**(-2),
    				data.objFeatures[i,data.cellFeatureIds['Location_Center_Y']] * 10**(-2),
    				data.objFeatures[i,data.cellFeatureIds['AreaShape_Area']] * 10**(-4),
    				data.objFeatures[i,data.cellFeatureIds['AreaShape_Perimeter']] * 10**(-2),
    				data.objFeatures[i,data.nucleusFeatureIds['AreaShape_Area']] * 10**(-3),
    				data.objFeatures[i,data.nucleusFeatureIds['AreaShape_Perimeter']] * 10**(-2),
    				i
    			)
    		)
    	fout.close()
        
    
    # output data in mahalanobis space + mahalanobis distance
    if len(sys.argv) > 4:
        #for i in xrange(trans_features.shape[0]):
       # 	dist = numpy.sum(trans_features[i,:]**2)
       # 	d_mahal[i] = dist
        tmp_array = numpy.array(0.0)
        tmp_array.resize(len(data.treatments[treatmentControl].cells))
        for i in xrange(tmp_array.shape[0]):
            tmp_array[i] = d_mahal[i]
        medianMahalCtrl = numpy.median(tmp_array)
        meanMahalCtrl = numpy.mean(tmp_array)
        madMahalCtrl = numpy.mean(numpy.abs(tmp_array - meanMahalCtrl))
        mahalScore = (d_mahal - medianMahalCtrl) / madMahalCtrl
        fout = open(sys.argv[4],'wb')
        str = ''
        for i in xrange(trans_features.shape[1]):
        	str += 'feature %d\t' % i
        str += 'distance 1\tdistance 2\tmahalanobis_score\n'
        fout.write(str)
        for i in xrange(trans_features.shape[0]):
        	str = ''
        	for j in xrange(trans_features.shape[1]):
        		str += '%f\t' % trans_features[i,j]
        	dist = numpy.sum(trans_features[i,:]**2)
        	str += '%f\t%f\t%f\n' % (dist,d_mahal[i],mahalScore[i])
        	fout.write(str)
        fout.close()
    
    # cluster data points in mahalanobis space
    partition,clusters = cluster.cluster_by_dist(trans_features, 3)
    
    # output clustering
    if len(sys.argv) > 5:
    	cluster_count = numpy.zeros(clusters.shape[0])
    	for i in xrange(partition.shape[0]):
    		cluster_count[partition[i]] += 1
    	fout = open(sys.argv[5],'wb')
    	fout.write('clusters\n')
    	for i in xrange(clusters.shape[0]):
    		str = ''
    		for j in xrange(clusters.shape[1]):
    			str += '%f\t' % clusters[i,j]
    		str = str[:-1] + '\n'
    		fout.write(str)
    	fout.write('\n')
    	fout.write('cluster_count\n')
    	for i in xrange(cluster_count.shape[0]):
    		str = '%d\n' % cluster_count[i]
    		fout.write(str)
    	fout.write('\n')
    	fout.write('partitioning (rowId -> clusterId)\n')
    	str = 'rowId\tclusterId\t'
    	for i in xrange(trans_features.shape[1]):
    	    str += 'feature %d\t' % i
    	str += 'distance\n'
    	fout.write(str)
    	for i in xrange(partition.shape[0]):
    		str = '%d\t%d\t' % (i,partition[i])
    		for j in xrange(trans_features.shape[1]):
    			str += '%f\t' % trans_features[i,j]
    		dist = 0.0
    		for j in xrange(trans_features.shape[1]):
    			dist += (trans_features[i,j] - clusters[partition[i],j])**2
    		dist = numpy.sqrt(dist)
    		str += '%f\n' % dist
    		fout.write(str)
    	fout.close()


    # calculate the mahalanobis-distance matrix for all samples
    d_mahal_m = mahal_dist.mahalanobis_distance_between_all_points(ref, test)
    
    def mds(dist_m, M):
    
        A_m = - 0.5 * dist_m
        A_row = numpy.mean(A_m,1)
        A_col = numpy.mean(A_m,0)
        A_scalar = numpy.mean(A_row)
        
        B_m = A_m + A_scalar
        B_m -= A_col
        B_m = B_m.transpose()
        B_m -= A_row
        B_m = B_m.transpose()
        
        eigvals,eigvecs = numpy.linalg.eig(B_m)
        eigvecs_len = numpy.sum(eigvecs**2,0)
        
        import pdb
        pdb.set_trace()
        
        eigvecs = eigvecs * numpy.sqrt(eigvals / eigvecs_len)
        
        sorting = numpy.argsort(eigvals)
        X = eigvecs[:,sorting[-1-M:-1]] * numpy.sqrt(eigvals[sorting[-1-M:-1]])
        
        return X
        
    X = mds(d_mahal_m, 2)
    
    
    # output MDS
    if len(sys.argv) > 6:
    	fout = open(sys.argv[6],'wb')
    	fout.write('x\ty\n')
    	for i in xrange(X.shape[0]):
    		str = '%f\t%f\n' % (X[i,0], X[i,1])
    		fout.write(str)
    	fout.close()






